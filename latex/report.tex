\documentclass[11pt]{article}

\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{2212}{\textendash}
\usepackage[top=2cm, bottom=2cm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{gensymb}
\usepackage[skip=0.5cm]{parskip}
\usepackage[english]{babel}
\usepackage[citestyle=ieee]{biblatex}
\usepackage{cleveref}
\usepackage{csquotes}
\usepackage{amsfonts}
\usepackage{float}
\usepackage{soul}
\usepackage{tabularx}
\usepackage{pgf}


\renewcommand{\thesection}{\Alph{section}}
\renewcommand{\thesubsection}{(\roman{subsection})}

\begin{document}
\input{titlepage.tex}
\newpage
\section{Modulation type feasibility}
\section{Power spectral density of 4-PAM}\label{rect_psd_section}
The power spectral density of a pulse-shaped data sequence is given by the
energy spectral density of the pulse shape multiplied by power spectral density
of the impulse chain (data sequence). The power spectral density of the impulse
chain can be found be calculating the Fourier transform of the autocorrelation
of the impulse chain.
\begin{equation}
    S_y(f) = |P(f)|^2S_x(f) = |P(f)|^2 \mathcal{F} \{ R_x(\tau) \}
\end{equation}
$R_x(\tau)$ is a continuous autocorrelation, but due to the fact that the data
is comprised of delta functions, $R_x(\tau)$ will only be non-zero when these
delta functions line up, ie. when $\tau$ is an integer multiple of the sampling
period $T_s$. Because of this, $R_x(\tau)$ can be represented as a sum rather
than an integral.

$R_n$ represents the value of the autocorrelation at an integer sample offset of
$n$. $N$ represents the window size in units of samples ($N = \frac{T}{T_s}$).
\begin{equation}\label{rn}
    R_n = \lim_{N \to \infty}  \frac{1}{N} \sum_{k} a_k a_{k-n}
\end{equation}

Since the continuous time correlation is only non-zero at multiples of sample
period, it can be represented as an impulse chain (ie. sum of time-offset delta
functions), where the height of each delta function is given by the discreet
autocorrelation value at that offset.
\begin{equation}\label{autocorr}
    R_x(\tau) = \frac{1}{T_s} \sum_{n=-\infty}^{\infty} R_n \delta(\tau - nT_s)
\end{equation}

\subsection{Calculating $R_n$\label{calcrn}}
From \Cref{rn}, we can see that the discreet autocorrelation values are
dependent on two adjacent values of $x[n]$. No specific data sequence is given
in the question, so I will assume the input data is random. A table of all the
possible combinations of adjacent signals can be produced. Since this is 4-PAM,
the possible values for a single sample are $x[n] \in \{-3, -1, 1, 3\}$.
\begin{table}[H]
    \begin{center}
        \begin{tabular}{c|c c c c}
               & -3 & -1 & 1  & 3  \\
            \hline
            -3 & 9  & 3  & -3 & -9 \\
            -1 & 3  & 1  & -1 & -3 \\
            1  & -3 & -1 & 1  & 3  \\
            3  & -9 & -3 & 3  & 9
        \end{tabular}
    \end{center}
    \caption{Symbol combinations\label{combos}}
\end{table}
From \Cref{combos}, there are 16 possibilities for adjacent symbol
multiplication. $\pm\{1, 9\}$ occur twice each, while $\pm 3$ occur four
times each. Over a suffiently long dataset, the sum in \Cref{rn} will become an
average of all the combinations.
\begin{equation}
    \begin{gathered}
        \frac{1}{N} \sum_k a_k a_{k-n} = \frac{2}{16}(1) + \frac{2}{16}(-1) +
        \frac{2}{16}(9) + \frac{2}{16}(-9) + \frac{4}{16}(3) + \frac{4}{16}(-3)
        \\
        \frac{1}{N} \sum_k a_k a_{k-n} = 0
    \end{gathered}
\end{equation}

\subsection{Calculating $R_0$}
$R_0$ is the autocorrelation of the impulse chain at time of zero. The sum from
\Cref{rn} becomes
\begin{equation}
    \lim_{N \to \infty}  \frac{1}{N}\sum_k a_k^2
\end{equation}
Like in \Cref{calcrn}, it can be assumed that all possibilities of $\{-3, -1, 1,
    3\}$ are equally likelely, and the sum becomes the average.
\begin{equation}
    R_0 = \frac{1}{4}(-3)^2 + \frac{1}{4}(-1)^2 + \frac{1}{4}(1)^2 +
    \frac{1}{4}(3)^2 = 5
\end{equation}

\subsection{Calculating PSD}
From \Cref{autocorr}, since $R_n$ is zero for all $n\neq 0$:
\begin{equation}
    R_x(\tau) = R_0 \delta(\tau)
\end{equation}
\begin{equation}
    R_x(f) = \mathcal{F}\{\frac{5}{T_s} \delta(\tau)\} = \frac{5}{T_s} = S_x(f)
\end{equation}
\begin{equation}
    \begin{gathered}
        S_y(f) = |P(f)|^2S_x(f) = S_x(f) \int_{-\infty}^{\infty} rect(T_s)
        \,dt\\
        S_y(f) = \frac{5}{T_s}T_s = \boldsymbol 5
    \end{gathered}
\end{equation}


\section{Design of pulse shape}
A raised cosine filter is used for pulse shaping. Choose $B_T = 750KHz$ and
$\alpha = 1$ so that the filter produces maximum power transfer while staying
within the bandwidth limit.
\begin{figure}[H]
    \centering
    \scalebox{0.7}{\input{plots/rcos_psd.pgf}}
    \caption{Power spectral density of raised cosine filter\label{psdgraph}}
\end{figure}
The PSD calculated in \Cref{rect_psd_section} (using a rect pulse shape) has a
flat frequency response across all frequencies. This is not possible to transmit
as it requires infinite energy. It also violates the 750KHz bandwidth limit. The
raised cosine pulse shape constrains the PSD to lie within the bandwith limits.

\section{Baseband transmission simulation}
\begin{figure}[H]
    \centering
    \scalebox{0.7}{\input{plots/baseband_tx.pgf}}
    \caption{Baseband delta chain and pulse shaped output\label{bbtxgraph}}
\end{figure}

\section{Ideal channel eye diagram}
\begin{figure}[H]
    \centering
    \scalebox{0.7}{\input{plots/eye_diagram.pgf}}
    \caption{Eye diagram and sampling instant for a perfect channel}
\end{figure}

\section{AWGN effect}
An addition of additive white gaussian noise in the channel will cause the eye
to `close' more than in the perfect channel case.

To simulate this, the noise power needs to be calculated. The average energy per
symbol can be calculated as follows, where $E_p$ is the energy of a pulse.
\begin{equation}
    E_p = \int_{-\infty}^{\infty} |p(t)|^2 \,dt
\end{equation}
Given a value for $\frac{E_b}{N_0}$, the value for $N_0$ can be calculated as
follows:
\begin{equation}
    N_0 = \left(\frac{E_b}{N_0} \right)^{-1} E_b
\end{equation}
For the filter selected in the baseband receiver simulation, the energy is
normalized such that $E_b = 1$. To generate noise to add to the channel, $N_0$
was used as the variance of a randomly sampled gaussian variable. The standard
deviation is given by $\sqrt{N_0}$. AWGN always has a mean $\mu = 0$.

\begin{figure}[H]
    \centering
    \scalebox{0.7}{\input{plots/awgn_eye_diagram.pgf}}
    \caption{Eye diagram with AWGN, $\frac{E_b}{N_0} = 10dB$}
\end{figure}

\section{4-PAM Detector}
To produce a 4-PAM thresholding detector, thresholds were chosen at $\{-2, 0,
    2\}$. These thresholds are in the midpoint between symbol signal levels.
This was chosen because AWGN causes symbol errors at the same rate irregardless
of which symbol is being transmitted. The detector samples at the ideal sampling
instant.


The detector was run with AWGN in the channel for a variety of $\frac{E_b}{N_0}$
values. Theoretical error rate was calculated using
\begin{equation}
    R_e = Q\left( \sqrt{2 \frac{E_b}{N_0}}\right)
\end{equation}

\begin{figure}[H]
    \centering
    \scalebox{0.7}{\input{plots/error_rate.pgf}}
    \caption{Bit error rate for simulated channel\label{error}}
\end{figure}

\begin{figure}[H]
    \centering
    \scalebox{0.7}{\input{plots/error_rate_log.pgf}}
    \caption{Bit error rate for simulated channel, log Y axis\label{errorlog}}
\end{figure}

As shown in \Cref{error}, the bit error rate is nearly zero for higher values of
$\frac{E_b}{N_0}$. This is very apparent in \Cref{errorlog}, where the error
rate is zero and therefor undefined/$-\infty$ on a log scale. The SNR of these
data points is high enough that not a single bit error occurs in the 10000
simulated bits. In order to predict the BER for these values of
$\frac{E_b}{N_0}$, a much longer bit stream would need to be simulated to
trigger enough bit errors to get a good statistical sample.

\section{ISI and Equalization}
\begin{equation}\label{ysum}
    y[i] = \sum_{k=-\infty}^{\infty}  a_k h[i-k]+w[i]
\end{equation}
The sampled receiver output $y[i]$ is the sum over all transmitted symbols $a_k$
multiplied by the effective channel filter at the offset of each symbol. This
models ISI because the recieved sample may be influenced by other transmitted
samples ($a_k$) if the impulse response of the effective channel filter at that
symbol ($h[i-k]$) is nonzero.

\begin{equation}\label{autocorr_exp}
    R_y[m] \triangleq E\left[ y[i+m] y^*[i]\right]
\end{equation}
For a wide sense stationary process, the autocorrelation of a signal is the
expected value of the random variable times it's conjugate. This is due to
autocorrelation effectively being a time delayed sum, which is a realization of
an average/mean, giving the expected value definition.

\begin{equation}\label{bigsum}
    R_y[m] = E \left[ \left( \sum_k a_k h[i+m-k]+w[i+m] \right) \left( \sum_j
        a_j^* h^*[i-j]+w^*[i] \right) \right]
\end{equation}
Plugging \Cref{ysum} into \Cref{autocorr_exp}.

\begin{equation}\label{symbol_ea}
    E[a_k a_j^*] =
    \begin{cases}
        E_a & j=k      \\
        0   & j \neq k
    \end{cases}
\end{equation}
This case is discussed in \Cref{rect_psd_section}. For any combination of
different symbols, there are an equal number of positive and negative results,
due to the symbol levels being spread around zero. Because of this, the mean
(expected value) of two disjoint symbols is zero. If a symbol is multiplied with
the conjugate of itself (equivalent to $|a_k|^2$), its expected value will be
the average of the squares of the symbol levels, represented here as $E_a$.

\begin{equation} \label{enoise_zero}
    E\left[a_k w^*[i]\right]= 0
\end{equation}
The expected value of AWGN $w^*[i]$ is $0$. Since the signals $a_k$ and $w^*[i]$
are statistically independent, $E\left[a_k w^*[i]\right]$ can be rewritten as
$E[a_k]E[w^*[i]] = E[a_k]\cdot 0 = 0$

\begin{equation}\label{noise_e}
    E \left[w[l]w^*[i]\right] =
    \begin{cases}
        \sigma^2_w = \frac{N_0}{2} & l = i    \\
        0                          & l \neq i
    \end{cases}
\end{equation}
Two samples of AWGN are independent. The expected value of any AWGN sample
$E[w[l]] = 0$. If two different samples are multiplied, the expected value will
also be zero ($E[xy] = E[x]E[y]$ for independent variables), hence
$E[w[l]w^*[i]] = 0$ for $l \neq i$. For a single sample ($l = i$), the expected
value is the energy of the noise $\frac{N_0}{2}$, which is also the variance of
the noise's gaussian distribution $\sigma_w^2$.

\begin{equation}
    R_y[m] = E\left[ \left( \sum_k a_k h[i+m-k] + \sum_k w[i+m] \right) \left(
        \sum_j a_j^* h^*[i-j] + \sum_j w^*[i] \right) \right]
\end{equation}
Distribute sum operators from \Cref{bigsum}.

\begin{align}
    \begin{split}
        R_y[m] = & \\
        & E\left[ \sum_k a_k h[i+m-k] \sum_j a_j^* h^*[i-j] \right] + \\
        & E\left[ \sum_k a_k h[i+m-k] \sum_j w^*[i] \right] +         \\
        & E\left[ \sum_k w[i+m] \sum_j a_j^* h^*[i-j] \right] +       \\
        & E\left[ \sum_k w[i+m] \sum_j w^*[i] \right]
    \end{split}
\end{align}
Multilply the two binomials.

\begin{equation}
    R_y[m] = E\left[ \sum_k a_k h[i+m-k] \sum_j a_j^* h^*[i-j] \right] + E\left[
        \sum_k w[i+m] \sum_j w^*[i] \right]
\end{equation}
Using the \Cref{enoise_zero}, we are able to eliminate the second and third
terms, since they include an expected value for the AWGN, which is zero.

\begin{equation}
    \therefore R_y[m] = \sum_k E_a h[i+m-k]h^*[i-k]+\frac{N_0}{2}\delta[m]
\end{equation}
Using \Cref{symbol_ea}, the expected value of the product $a_k a_j^*$ is equal
to $E_a$. Using \Cref{noise_e}, the expected value of the product $w[i+m]w^*[i]$
is zero except for when $j = k$, ie.  at the sample $m$, when it is
$\frac{N_0}{2}$. This can be represented by a delta function at time $m$. The
filter coefficients $h[x]$ and $h^*[x]$ are left intact.

\begin{equation}
    R_y[m] = E_a \sum_j h[m+j]h^*[j]+\frac{N_0}{2}\delta[m]
\end{equation}
Pull $E_a$ out of the sum, and set $j = i - k$ as the sum iterator.

\section{MMSE equaliser simulation}

\subsection{MATLAB plots}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{plots/multipath_eye.eps}
    \caption{Eye diagram without equaliser\label{badeye}}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{plots/symbol_error_eq.eps}
    \caption{Symbol error probability with and without equaliser\label{eq_err}}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{plots/constellation_eq.eps}
    \caption{Signal amplitude levels (constellation) with and without
        equaliser\label{constellation}}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{plots/channel_impulse.eps}
    \caption{Impulse response of multipath channel}
\end{figure}

\subsection{Analysis}
Equalization can greatly improve the performance of a communication system.
Prior to use of an equalizer, the `eye' is completely closed as shown in
\Cref{badeye}. There is no margin over noise. After equalization, a larger
margin over noise is produced, meaning the eye is `open' and signals can be
decoded with an error rate less than 100\%. This difference can be shown in the
constellations in \Cref{constellation}, with gaps showing margin over noise only
appearing after equalization.

Due to there being zero margin over noise prior to equalization, the receiver is
effectively sampling nothing but ISI noise. Because of this, the error rate is a
flat 60\% for all SNRs, illustrated by the `without equalizer' plot in
\Cref{eq_err}.



\section{Lab Exercise}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{scope.png}
    \caption{Oscilloscope output for signal generator \textbf{A}\label{scope}}
\end{figure}
\subsection{Steps required to generate image}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{scope_setup.png}
    \caption{Experiment setup}
\end{figure}
These steps can be used to generate an eye diagram on a generic digital storage
oscilloscope:
\begin{enumerate}
    \item Connect the signal and clock outputs of the signal generator to two
          input channels of the oscilloscope.
    \item Set the trigger of the oscilloscope to use the clock channel.
    \item Adjust the trigger level to approximately half of the maximum
          amplitude of the clock signal, about 2.5V in this case. Any trigger
          level such that the refresh is only triggered on the edge of a pulse
          will work (ie. not above the max amplitude but not below the noise
          threshold of a clock `0' output).
    \item Adjust the horizontal scaling factor of the oscilloscope such that
          about three clock pulses are visible in the oscilloscope output
          window.
    \item Adjust the vertical scaling of both the signal and clock waveforms so
          main features are visible and large enough to measure using the volts
          per division and grid.
    \item Turn the persistence of the oscilloscope to maximum ($\infty$)
    \item If the image needs to be adjusted (scaled or horizontally offset), the
          persistence must be cleared.
\end{enumerate}

\subsection{Modulation type}
As shown in \Cref{scope}, the signal output shows four main levels at the eye
open instant. These are levels of voltage (signal \textit{amplitude}). Because
of this, the modulation type is 4-PAM.

\subsection{Signal characteristics}
\paragraph{Symbol rate}
The symbol rate is the frequency at which symbols are transmitted, which can be
found by the reciprocal of the time between clock pulses. Measured at 2.66KHz.
\paragraph{Error free sampling interval}
The error free sampling interval is the horizontal distance between the
left-most and right-most corners of the eye. In this interval, the signal has
settled in to one of the threshold regions for symbol decoding and will be
correctly decoded. Measured at 260us.
\paragraph{Margin over noise}
Noise margin is the voltage difference between a threshold (the horizontal axis
of the eye) and the maximum value of a noisy signal at the widest opening point
of the eye. If the signal were to be distorted by more than this margin, it
would cause a bit error even with if the sampling instant was chosen optimally.
Measured at 200mV.
\paragraph{Level crossing timing jitter}
Level crossing jitter is the variation in when signals cross the threshold
level. It shows the clock stability of the transmitter or phase distortion in
the transmission medium. Measured at 120us.

\subsection{Sensitivity of signal to timing error}
The error free sampling interval (260us) is a large proportion (approximately
70\%) of the entire symbol period (376us). Because of this, errors in timing
will be tolerated well, provided the timing error is not cumulative. If the
timing error is purely a phase error, a wide range of errors will be tolerated.
If the timing error is a sampling frequency error (ie. desynchronization of
local oscillators), the symbols will become corrupted as the RX sampling
oscillator moves out of the 260us window.

An eye diagram with a large error free sampling period may signify the signal
has not been band limited inside the bandwidth of the original TX pulse shape.
Since the measured signal exhibits this characteristic, it has not been band
limited.
\end{document}